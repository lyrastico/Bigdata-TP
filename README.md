# üß† Big Data ‚Äì DataLake IA (Google Trends & Actualit√©s)

Projet r√©alis√© dans le cadre du module **Architecture Big Data ‚Äì DataLake**.  
L‚Äôobjectif est de construire un pipeline complet d‚Äôingestion, de persistance et de visualisation autour du th√®me :

# üéØ Analyse de l‚Äô√©volution de l‚Äôint√©r√™t mondial pour l‚ÄôIntelligence Artificielle

Ce projet combine deux sources de donn√©es **h√©t√©rog√®nes** :

1. **Google Trends (CSV)** ‚Äì int√©r√™t du public pour :  
   - ‚Äúia‚Äù  
   - ‚Äúdeep learning‚Äù  
   - ‚Äúchatgpt‚Äù

2. **Google News RSS (XML / RSS)** ‚Äì nombre d‚Äôarticles publi√©s sur **‚Äúintelligence artificielle‚Äù**

Ces donn√©es sont ing√©r√©es en batch, stock√©es dans une couche raw, transform√©es puis envoy√©es dans un Data Warehouse Postgres, et visualis√©es via Streamlit.

---

# üìå Sujet du projet

L‚Äôobjectif est de construire une architecture DataLake comprenant :

- Ingestion (CSV + RSS)  
- Nettoyage et transformation  
- Stockage raw + Data Warehouse  
- Dashboard Insight interactif  

Le th√®me choisi :  
> √âtudier l‚Äô√©volution de l‚Äôint√©r√™t mondial pour l‚ÄôIntelligence Artificielle, ainsi que son niveau de m√©diatisation, puis explorer d‚Äô√©ventuelles corr√©lations.

---

# üîé Sources de donn√©es utilis√©es

## 1. Google Trends (CSV)

Google Trends fournit un score hebdomadaire (0‚Äì100) indiquant √† quel point un terme est recherch√©.  
Mots-cl√©s utilis√©s :

- `ia`
- `deep learning`
- `chatgpt`

Exemple de CSV :

```
Semaine, deep learning
2020-11-22, 15
2020-11-29, 16
```

Ce sont des donn√©es historiques permettant d‚Äôanalyser les tendances du public.

---

## 2. Google News RSS (Actualit√©s IA)

Flux RSS Google News :  
`https://news.google.com/rss/search?q=intelligence+artificielle`

Chaque article contient :

- un titre  
- une date de publication  
- une source m√©dia  

Les donn√©es sont nettoy√©es puis agr√©g√©es **par semaine**, donnant :

| event_time | metric_1 | category |
|------------|----------|----------|
| 2025-11-17 | 42       | news_ia  |
| 2025-11-24 | 18       | news_ia  |

---

# üß© Pourquoi combiner ces deux sources ?

Parce qu‚Äôensemble, elles permettent d‚Äô√©tudier l‚Äô√©cosyst√®me IA :

### üîµ Google Trends ‚Üí int√©r√™t du public  
### üü† Google News ‚Üí m√©diatisation dans les m√©dias  

Cela permet de voir :

- si les pics de recherche correspondent aux pics d‚Äôactualit√©  
- l‚Äôimpact m√©diatique de ChatGPT  
- la diff√©rence entre int√©r√™t g√©n√©ral (IA) et int√©r√™t technique (deep learning)

---

# üèóÔ∏è Architecture du projet

```
             +----------------------+
             | Google Trends (CSV)  |
             +----------+-----------+
                        |
                        v
                ingest_csv_batch.py
                        |
                +-------+-------+
                |     Raw       |
                +-------+-------+
                        |
             +----------+-----------+
             | Google News (RSS)    |
             +----------+-----------+
                        |
                        v
               ingest_news_batch.py
                        |
                        v
           +------------+-------------+
           | ETL ‚Üí Postgres (DW)      |
           +------------+-------------+
                        |
                        v
                  Dashboard Insight
                 (Streamlit, filters)
```

---

# üöÄ Installation & Lancement

## 1. Cloner

```powershell
git clone https://github.com/lyrastico/Bigdata-TP.git
cd Bigdata-TP
```

## 2. Installer Python

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

## 3. Lancer Postgres (Docker)

```powershell
docker-compose up -d
```

Cr√©er les tables :

```powershell
Get-Content .\persistence\create_tables.sql | docker exec -i datalake_postgres psql -U datalake_user -d datalake_db
```

## 4. Ingestion

### Google Trends

```powershell
python ingestion\ingest_csv_batch.py
```

### Actualit√©s IA

```powershell
python ingestion\ingest_news_batch.py
```

## 5. ETL vers Postgres

```powershell
python persistence\load_to_warehouse.py
```

## 6. Dashboard

```powershell
streamlit run insight\dashboard_streamlit.py
```

---

# ‚ôªÔ∏è R√©initialiser compl√®tement les donn√©es

## 1. Vider Postgres

```powershell
docker exec -it datalake_postgres psql -U datalake_user -d datalake_db
```

Dans psql :

```sql
TRUNCATE TABLE fact_event, dim_source RESTART IDENTITY;
\q
```

## 2. Supprimer Raw & Processed

```powershell
Remove-Item data\raw\* -Force
Remove-Item data\processed\* -Force
```

## 3. Re-ing√©rer

```powershell
python ingestion\ingest_csv_batch.py
python ingestion\ingest_news_batch.py
python persistence\load_to_warehouse.py
```

---

# üë• Auteurs

Projet r√©alis√© dans le cadre du module Big Data ‚Äì DataLake (IPSSI).
